{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import os\n",
    "#dirname = os.path.dirname(__file__)\n",
    "#filename = os.path.join(dirname, '../deeplog')\n",
    "\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from bert_pytorch.dataset import WordVocab\n",
    "from bert_pytorch import Predictor, Trainer\n",
    "from bert_pytorch.dataset.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options = dict()\n",
    "options['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "options[\"output_dir\"] = \"../output/hdfs/\"\n",
    "options[\"model_dir\"] = options[\"output_dir\"] + \"bert/\"\n",
    "options[\"model_path\"] = options[\"model_dir\"] + \"best_bert.pth\"\n",
    "options[\"train_vocab\"] = options[\"output_dir\"] + \"train\"\n",
    "options[\"vocab_path\"] = options[\"output_dir\"] + \"vocab.pkl\"  # pickle file\n",
    "\n",
    "options[\"window_size\"] = 128\n",
    "options[\"adaptive_window\"] = True\n",
    "options[\"seq_len\"] = 512\n",
    "options[\"max_len\"] = 512 # for position embedding\n",
    "options[\"min_len\"] = 10\n",
    "options[\"mask_ratio\"] = 0.65\n",
    "# sample ratio\n",
    "options[\"train_ratio\"] = 1\n",
    "options[\"valid_ratio\"] = 0.1\n",
    "options[\"test_ratio\"] = 1\n",
    "\n",
    "# features\n",
    "options[\"is_logkey\"] = True\n",
    "options[\"is_time\"] = False\n",
    "\n",
    "options[\"hypersphere_loss\"] = True\n",
    "options[\"hypersphere_loss_test\"] = False\n",
    "\n",
    "options[\"scale\"] = None # MinMaxScaler()\n",
    "options[\"scale_path\"] = options[\"model_dir\"] + \"scale.pkl\"\n",
    "\n",
    "# model\n",
    "options[\"hidden\"] = 256 # embedding size\n",
    "options[\"layers\"] = 4\n",
    "options[\"attn_heads\"] = 4\n",
    "\n",
    "options[\"epochs\"] = 5 #200\n",
    "options[\"n_epochs_stop\"] = 10\n",
    "options[\"batch_size\"] = 32\n",
    "\n",
    "options[\"corpus_lines\"] = None\n",
    "options[\"on_memory\"] = True\n",
    "options[\"num_workers\"] = 5\n",
    "options[\"lr\"] = 1e-3\n",
    "options[\"adam_beta1\"] = 0.9\n",
    "options[\"adam_beta2\"] = 0.999\n",
    "options[\"adam_weight_decay\"] = 0.00\n",
    "options[\"with_cuda\"]= True\n",
    "options[\"cuda_devices\"] = None\n",
    "options[\"log_freq\"] = None\n",
    "\n",
    "# predict\n",
    "options[\"num_candidates\"] = 6\n",
    "options[\"gaussian_mean\"] = 0\n",
    "options[\"gaussian_std\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n",
      "features logkey:True time: False\n",
      "\n",
      "mask ratio 0.65\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed=1234)\n",
    "\n",
    "if not os.path.exists(options['model_dir']):\n",
    "    os.makedirs(options['model_dir'], exist_ok=True)\n",
    "\n",
    "print(\"device\", options[\"device\"])\n",
    "print(\"features logkey:{} time: {}\\n\".format(options[\"is_logkey\"], options[\"is_time\"]))\n",
    "print(\"mask ratio\", options[\"mask_ratio\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-s', '--std'], dest='std', nargs=None, const=None, default=1, type=<class 'float'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "parser = argparse.ArgumentParser()\n",
    "subparsers = parser.add_subparsers()\n",
    "\n",
    "train_parser = subparsers.add_parser('train')\n",
    "train_parser.set_defaults(mode='train')\n",
    "\n",
    "predict_parser = subparsers.add_parser('predict')\n",
    "predict_parser.set_defaults(mode='predict')\n",
    "predict_parser.add_argument(\"-m\", \"--mean\", type=float, default=0)\n",
    "predict_parser.add_argument(\"-s\", \"--std\", type=float, default=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvocab_parser = subparsers.add_parser(\\'vocab\\')\\nvocab_parser.set_defaults(mode=\\'vocab\\')\\nvocab_parser.add_argument(\"-s\", \"--vocab_size\", type=int, default=None)\\nvocab_parser.add_argument(\"-e\", \"--encoding\", type=str, default=\"utf-8\")\\nvocab_parser.add_argument(\"-m\", \"--min_freq\", type=int, default=1)\\n\\nargs = parser.parse_args()\\nprint(\"arguments\", args)\\n\\nif args.mode == \\'train\\':\\n    Trainer(options).train()\\n\\nelif args.mode == \\'predict\\':\\n    Predictor(options).predict()\\n\\nelif args.mode == \\'vocab\\':\\n    with open(options[\"train_vocab\"], \"r\", encoding=\"utf-8\") as f:\\n        texts = f.readlines()\\n    vocab = WordVocab(texts, max_size=None, min_freq=1)\\n    print(\"VOCAB SIZE:\", len(vocab))\\n    print(\"save vocab in\", options[\"vocab_path\"])\\n    vocab.save_vocab(options[\"vocab_path\"])\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "vocab_parser = subparsers.add_parser('vocab')\n",
    "vocab_parser.set_defaults(mode='vocab')\n",
    "vocab_parser.add_argument(\"-s\", \"--vocab_size\", type=int, default=None)\n",
    "vocab_parser.add_argument(\"-e\", \"--encoding\", type=str, default=\"utf-8\")\n",
    "vocab_parser.add_argument(\"-m\", \"--min_freq\", type=int, default=1)\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(\"arguments\", args)\n",
    "\n",
    "if args.mode == 'train':\n",
    "    Trainer(options).train()\n",
    "\n",
    "elif args.mode == 'predict':\n",
    "    Predictor(options).predict()\n",
    "\n",
    "elif args.mode == 'vocab':\n",
    "    with open(options[\"train_vocab\"], \"r\", encoding=\"utf-8\") as f:\n",
    "        texts = f.readlines()\n",
    "    vocab = WordVocab(texts, max_size=None, min_freq=1)\n",
    "    print(\"VOCAB SIZE:\", len(vocab))\n",
    "    print(\"save vocab in\", options[\"vocab_path\"])\n",
    "    vocab.save_vocab(options[\"vocab_path\"])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4855/4855 [00:00<00:00, 124502.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE: 20\n",
      "save vocab in ../output/hdfs/vocab.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(options[\"train_vocab\"], \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = f.readlines()\n",
    "vocab = WordVocab(texts, max_size=None, min_freq=1)\n",
    "print(\"VOCAB SIZE:\", len(vocab))\n",
    "print(\"save vocab in\", options[\"vocab_path\"])\n",
    "vocab.save_vocab(options[\"vocab_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save options parameters\n",
      "Loading vocab ../output/hdfs/vocab.pkl\n",
      "vocab Size:  20\n",
      "\n",
      "Loading Train Dataset\n",
      "before filtering short session\n",
      "train size  4370\n",
      "valid size  485\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4855/4855 [00:00<00:00, 32367.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Num of train seqs 4370\n",
      "Num of valid seqs 485\n",
      "========================================\n",
      "\n",
      "Loading valid Dataset\n",
      "Creating Dataloader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Jad\\AI_Projects\\AnomalyDetection_Transformers\\HDFS\\..\\bert_pytorch\\dataset\\sample.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  logkey_seq_pairs = np.array(logkey_seq_pairs)\n",
      "c:\\Jad\\AI_Projects\\AnomalyDetection_Transformers\\HDFS\\..\\bert_pytorch\\dataset\\sample.py:91: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  time_seq_pairs = np.array(time_seq_pairs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BERT model\n",
      "Creating BERT Trainer\n",
      "Total Parameters: 2120213\n",
      "Training Start\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:10<00:00, 13.16it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | phase: train, loss=3.0110111569657043\n",
      "logkey loss: 2.8877193910234116, hyper loss: 1.232917523559402\n",
      "\n",
      "Epoch: 0 | phase: valid, loss=2.587948751449585\n",
      "logkey loss: 2.4607895692189534, hyper loss: 1.2715916633605957\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:14<00:00,  9.10it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | phase: train, loss=2.217914061511264\n",
      "logkey loss: 2.099985023631769, hyper loss: 1.1792903963257284\n",
      "\n",
      "Epoch: 1 | phase: valid, loss=2.0336508750915527\n",
      "logkey loss: 1.9163018465042114, hyper loss: 1.1734902620315553\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:20<00:00,  6.57it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | phase: train, loss=1.569672406596296\n",
      "logkey loss: 1.4641168985296698, hyper loss: 1.0555551065241588\n",
      "\n",
      "Epoch: 2 | phase: valid, loss=1.3381215612093607\n",
      "logkey loss: 1.2354914704958597, hyper loss: 1.026300831635793\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:13<00:00, 10.04it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | phase: train, loss=1.1296120601541855\n",
      "logkey loss: 1.0377579186769093, hyper loss: 0.9185414011864101\n",
      "\n",
      "Epoch: 3 | phase: valid, loss=1.1539129694302876\n",
      "logkey loss: 1.066323443253835, hyper loss: 0.8758952895800273\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:17<00:00,  7.82it/s]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | phase: train, loss=0.9957147709587041\n",
      "logkey loss: 0.9153195084894404, hyper loss: 0.8039526014643557\n",
      "\n",
      "Epoch: 4 | phase: valid, loss=1.0873385190963745\n",
      "logkey loss: 1.009879038731257, hyper loss: 0.7745948513348897\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:13<00:00, 10.46it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | phase: train, loss=0.9354423122370944\n",
      "logkey loss: 0.8641240739208811, hyper loss: 0.7131823792177088\n",
      "\n",
      "Epoch: 5 | phase: valid, loss=1.0291666785875957\n",
      "logkey loss: 0.9594329178333283, hyper loss: 0.6973376830418905\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:14<00:00,  9.46it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | phase: train, loss=0.8749585830990005\n",
      "logkey loss: 0.809284627875861, hyper loss: 0.6567395443425459\n",
      "\n",
      "Epoch: 6 | phase: valid, loss=0.9914944410324097\n",
      "logkey loss: 0.926991327603658, hyper loss: 0.6450310985247294\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:14<00:00,  9.26it/s]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | phase: train, loss=0.8243527392692426\n",
      "logkey loss: 0.7631776587051504, hyper loss: 0.6117508367580526\n",
      "\n",
      "Epoch: 7 | phase: valid, loss=0.9156682352224986\n",
      "logkey loss: 0.8555471142133076, hyper loss: 0.6012111981709798\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:14<00:00,  9.48it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | phase: train, loss=0.7594548731165773\n",
      "logkey loss: 0.7015656302956974, hyper loss: 0.5788924435482306\n",
      "\n",
      "Epoch: 8 | phase: valid, loss=0.8900778969128926\n",
      "logkey loss: 0.8333074788252512, hyper loss: 0.5677042444547017\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:12<00:00, 11.21it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | phase: train, loss=0.6951654952238587\n",
      "logkey loss: 0.6398424333071008, hyper loss: 0.5532306125935387\n",
      "\n",
      "Epoch: 9 | phase: valid, loss=0.8209211150805156\n",
      "logkey loss: 0.7667913913726807, hyper loss: 0.5412972728411357\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:11<00:00, 11.41it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | phase: train, loss=0.6465052565669313\n",
      "logkey loss: 0.5944771705304875, hyper loss: 0.5202808665002093\n",
      "\n",
      "Epoch: 10 | phase: valid, loss=0.7878033816814423\n",
      "logkey loss: 0.7362232426802318, hyper loss: 0.5158014277617137\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:13<00:00, 10.40it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | phase: train, loss=0.5962311071069801\n",
      "logkey loss: 0.5473439233268008, hyper loss: 0.48887182574938326\n",
      "\n",
      "Epoch: 11 | phase: valid, loss=0.7204515099525451\n",
      "logkey loss: 0.6723621527353922, hyper loss: 0.4808935602506002\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "best radius 11.750147710410632\n",
      "Save best center ../output/hdfs/bert/best_center.pt\n",
      "save total dist:  ../output/hdfs/bert/best_total_dist.pt\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:12<00:00, 10.95it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | phase: train, loss=0.5598080340115463\n",
      "logkey loss: 0.5138167925179005, hyper loss: 0.45991241384078474\n",
      "\n",
      "Epoch: 12 | phase: valid, loss=0.7382412632306417\n",
      "logkey loss: 0.692036751906077, hyper loss: 0.4620451807975769\n",
      "\n",
      "Log saved\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:12<00:00, 11.30it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | phase: train, loss=0.5333982305053402\n",
      "logkey loss: 0.4893777000115198, hyper loss: 0.44020531129311113\n",
      "\n",
      "Epoch: 13 | phase: valid, loss=0.7254605809847514\n",
      "logkey loss: 0.6827278236548106, hyper loss: 0.4273276646931966\n",
      "\n",
      "Log saved\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 13.84it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | phase: train, loss=0.5038261470549247\n",
      "logkey loss: 0.4623278321369606, hyper loss: 0.41498315290493126\n",
      "\n",
      "Epoch: 14 | phase: valid, loss=0.7142116169134776\n",
      "logkey loss: 0.6735062817732493, hyper loss: 0.40705327192942303\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "best radius 10.815278504352628\n",
      "Save best center ../output/hdfs/bert/best_center.pt\n",
      "save total dist:  ../output/hdfs/bert/best_total_dist.pt\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 14.03it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | phase: train, loss=0.48685005581115975\n",
      "logkey loss: 0.44731930007829385, hyper loss: 0.39530755075461727\n",
      "\n",
      "Epoch: 15 | phase: valid, loss=0.6424279709657034\n",
      "logkey loss: 0.6037163178126017, hyper loss: 0.3871165156364441\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "best radius 10.541725625319513\n",
      "Save best center ../output/hdfs/bert/best_center.pt\n",
      "save total dist:  ../output/hdfs/bert/best_total_dist.pt\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:11<00:00, 11.81it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | phase: train, loss=0.4536552248413072\n",
      "logkey loss: 0.4164041118586765, hyper loss: 0.3725111278540948\n",
      "\n",
      "Epoch: 16 | phase: valid, loss=0.5942169884840648\n",
      "logkey loss: 0.5570173343022664, hyper loss: 0.3719964146614075\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "best radius 10.232104519839163\n",
      "Save best center ../output/hdfs/bert/best_center.pt\n",
      "save total dist:  ../output/hdfs/bert/best_total_dist.pt\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 13.77it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | phase: train, loss=0.4329286414910765\n",
      "logkey loss: 0.3973518909119508, hyper loss: 0.35576751828193665\n",
      "\n",
      "Epoch: 17 | phase: valid, loss=0.5879638075828553\n",
      "logkey loss: 0.5533760567506154, hyper loss: 0.3458775500456492\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "best radius 9.971312572767372\n",
      "Save best center ../output/hdfs/bert/best_center.pt\n",
      "save total dist:  ../output/hdfs/bert/best_total_dist.pt\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 14.17it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | phase: train, loss=0.4199684035471257\n",
      "logkey loss: 0.38623375883873773, hyper loss: 0.33734644072897296\n",
      "\n",
      "Epoch: 18 | phase: valid, loss=0.5914391169945399\n",
      "logkey loss: 0.5586923976739248, hyper loss: 0.3274671812852224\n",
      "\n",
      "Log saved\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 14.00it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | phase: train, loss=0.41759675270056024\n",
      "logkey loss: 0.3854985368602416, hyper loss: 0.320982164100689\n",
      "\n",
      "Epoch: 19 | phase: valid, loss=0.5025483320156733\n",
      "logkey loss: 0.4711127867301305, hyper loss: 0.31435544888178507\n",
      "\n",
      "Log saved\n",
      " Model Saved on: ../output/hdfs/bert/best_bert.pth\n",
      "best radius 9.492232706818696\n",
      "Save best center ../output/hdfs/bert/best_center.pt\n",
      "save total dist:  ../output/hdfs/bert/best_total_dist.pt\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 14.03it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | phase: train, loss=0.40024490983170624\n",
      "logkey loss: 0.3705356023548281, hyper loss: 0.2970930686330094\n",
      "\n",
      "Epoch: 20 | phase: valid, loss=0.5273593237002691\n",
      "logkey loss: 0.49832032521565756, hyper loss: 0.29038997292518615\n",
      "\n",
      "Log saved\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:10<00:00, 13.10it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | phase: train, loss=0.38484190075713043\n",
      "logkey loss: 0.35662519208648624, hyper loss: 0.28216708604903784\n",
      "\n",
      "Epoch: 21 | phase: valid, loss=0.503339676062266\n",
      "logkey loss: 0.47585426370302836, hyper loss: 0.2748541076978048\n",
      "\n",
      "Log saved\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:09<00:00, 13.97it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | phase: train, loss=0.37543097401366515\n",
      "logkey loss: 0.34853197765700955, hyper loss: 0.2689899521715501\n",
      "\n",
      "Epoch: 22 | phase: valid, loss=0.5171582192182541\n",
      "logkey loss: 0.49121428827444713, hyper loss: 0.25943929652372993\n",
      "\n",
      "Log saved\n",
      "\n",
      "\n",
      "start calculate center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:15<00:00,  8.72it/s]\n",
      "100%|██████████| 15/15 [00:02<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | phase: train, loss=0.373455986051875\n",
      "logkey loss: 0.34835695310988846, hyper loss: 0.2509903195588028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Trainer(options).train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/hdfs/bert/best_bert.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Jad\\AI_Projects\\AnomalyDetection_Transformers\\HDFS\\logbert.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/HDFS/logbert.ipynb#ch0000006?line=0'>1</a>\u001b[0m Predictor(options)\u001b[39m.\u001b[39;49mpredict()\n",
      "File \u001b[1;32mc:\\Jad\\AI_Projects\\AnomalyDetection_Transformers\\HDFS\\..\\bert_pytorch\\predict_log.py:230\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/HDFS/../bert_pytorch/predict_log.py?line=228'>229</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/HDFS/../bert_pytorch/predict_log.py?line=229'>230</a>\u001b[0m     model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_path)\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/HDFS/../bert_pytorch/predict_log.py?line=230'>231</a>\u001b[0m     model\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/HDFS/../bert_pytorch/predict_log.py?line=231'>232</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Jad\\AI_Projects\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=695'>696</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=696'>697</a>\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=698'>699</a>\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=699'>700</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=700'>701</a>\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=701'>702</a>\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=702'>703</a>\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=703'>704</a>\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Jad\\AI_Projects\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\torch\\serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=228'>229</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=229'>230</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=230'>231</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=231'>232</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=232'>233</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Jad\\AI_Projects\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\torch\\serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=210'>211</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> <a href='file:///c%3A/Jad/AI_Projects/AnomalyDetection_Transformers/.venv/lib/site-packages/torch/serialization.py?line=211'>212</a>\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/hdfs/bert/best_bert.pth'"
     ]
    }
   ],
   "source": [
    "Predictor(options).predict()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "182fe3b26f900d191053996287a94e64fbebd9ca1b4c644d38d8e1b9f7b6df61"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
