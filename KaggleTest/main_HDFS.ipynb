{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install plotly\n",
    "!pip install tqdm\n",
    "'''\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import LSTM, GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get [log key, delta time] as input for deeplog\n",
    "input_dir  = '../Datasets/hdfs/'\n",
    "output_dir = '../output/hdfs/'  # The output directory of parsing results\n",
    "log_file   = \"HDFS.log\"  # The input log file name\n",
    "\n",
    "log_structured_file = output_dir + log_file + \"_structured.csv\"\n",
    "log_templates_file = output_dir + log_file + \"_templates.csv\"\n",
    "log_sequence_file = output_dir + \"hdfs_sequence.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring TPU's as we will be using Bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train = logFile2DataFrame('../Datasets/HDFS/HDFS.log')\n",
    "#validation = pd.read_csv('../Datasets/Sentiment/validation.csv')\n",
    "#test = pd.read_csv('../Datasets/Sentiment/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def load_data(log_format):\n",
    "    headers, regex = generate_logformat_regex(log_format)\n",
    "    df_log = log_to_dataframe(os.path.join(input_dir, log_file), regex, headers, log_format)\n",
    "    return df_log\n",
    "\n",
    "def log_to_dataframe( log_file, regex, headers, logformat):\n",
    "    \"\"\" Function to transform log file to dataframe\n",
    "    \"\"\"\n",
    "    log_messages = []\n",
    "    linecount = 0\n",
    "    cnt = 0\n",
    "    with open(log_file, 'r') as fin:\n",
    "        for line in fin.readlines():\n",
    "            cnt += 1\n",
    "            try:\n",
    "                match = regex.search(line.strip())\n",
    "                message = [match.group(header) for header in headers]\n",
    "                log_messages.append(message)\n",
    "                linecount += 1\n",
    "            except Exception as e:\n",
    "                # print(\"\\n\", line)\n",
    "                # print(e)\n",
    "                pass\n",
    "    print(\"Total size after encoding is\", linecount, cnt)\n",
    "    logdf = pd.DataFrame(log_messages, columns=headers)\n",
    "    logdf.insert(0, 'LineId', None)\n",
    "    logdf['LineId'] = [i + 1 for i in range(linecount)]\n",
    "    return logdf\n",
    "\n",
    "def generate_logformat_regex( logformat):\n",
    "    \"\"\" Function to generate regular expression to split log messages\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    splitters = re.split(r'(<[^<>]+>)', logformat)\n",
    "    regex = ''\n",
    "    for k in range(len(splitters)):\n",
    "        if k % 2 == 0:\n",
    "            splitter = re.sub(' +', '\\\\\\s+', splitters[k])\n",
    "            regex += splitter\n",
    "        else:\n",
    "            header = splitters[k].strip('<').strip('>')\n",
    "            regex += '(?P<%s>.*?)' % header\n",
    "            headers.append(header)\n",
    "    regex = re.compile('^' + regex + '$')\n",
    "    return headers, regex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size after encoding is 3746105 3746106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Pid</th>\n",
       "      <th>Level</th>\n",
       "      <th>Component</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>081109</td>\n",
       "      <td>203518</td>\n",
       "      <td>143</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>081109</td>\n",
       "      <td>203518</td>\n",
       "      <td>35</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.FSNamesystem</td>\n",
       "      <td>BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>081109</td>\n",
       "      <td>203519</td>\n",
       "      <td>143</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>081109</td>\n",
       "      <td>203519</td>\n",
       "      <td>145</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>081109</td>\n",
       "      <td>203519</td>\n",
       "      <td>145</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$PacketResponder</td>\n",
       "      <td>PacketResponder 1 for block blk_-1608999687919...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineId    Date    Time  Pid Level                     Component  \\\n",
       "0       1  081109  203518  143  INFO      dfs.DataNode$DataXceiver   \n",
       "1       2  081109  203518   35  INFO              dfs.FSNamesystem   \n",
       "2       3  081109  203519  143  INFO      dfs.DataNode$DataXceiver   \n",
       "3       4  081109  203519  145  INFO      dfs.DataNode$DataXceiver   \n",
       "4       5  081109  203519  145  INFO  dfs.DataNode$PacketResponder   \n",
       "\n",
       "                                             Content  \n",
       "0  Receiving block blk_-1608999687919862906 src: ...  \n",
       "1  BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...  \n",
       "2  Receiving block blk_-1608999687919862906 src: ...  \n",
       "3  Receiving block blk_-1608999687919862906 src: ...  \n",
       "4  PacketResponder 1 for block blk_-1608999687919...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_format = '<Date> <Time> <Pid> <Level> <Component>: <Content>'  # HDFS log format\n",
    "train = load_data(log_format)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70833it [19:25, 60.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\KaggleTest\\main_HDFS.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=14'>15</a>\u001b[0m \u001b[39m'''        \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=15'>16</a>\u001b[0m \u001b[39m        df[\"BlockId\"]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=16'>17</a>\u001b[0m \u001b[39m        blkId_set = set(blkId_list)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=22'>23</a>\u001b[0m \u001b[39m    print(\"hdfs sampling done\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=23'>24</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=24'>25</a>\u001b[0m aaa_df \u001b[39m=\u001b[39m hdfs_sampling(train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=25'>26</a>\u001b[0m aaa_df\u001b[39m.\u001b[39mhead(\u001b[39m20\u001b[39m)\n",
      "\u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\KaggleTest\\main_HDFS.ipynb Cell 8'\u001b[0m in \u001b[0;36mhdfs_sampling\u001b[1;34m(df, window)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m tqdm(df\u001b[39m.\u001b[39miterrows()):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=6'>7</a>\u001b[0m     blkId_list \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(blk_-?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+)\u001b[39m\u001b[39m'\u001b[39m, row[\u001b[39m'\u001b[39m\u001b[39mContent\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=7'>8</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[idx] \u001b[39m=\u001b[39m blkId_list\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000024?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=712'>713</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=714'>715</a>\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=715'>716</a>\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1690\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=1687'>1688</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=1688'>1689</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=1689'>1690</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1939\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=1936'>1937</a>\u001b[0m \u001b[39m# actually do the set\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=1937'>1938</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39msetitem(indexer\u001b[39m=\u001b[39mindexer, value\u001b[39m=\u001b[39mvalue)\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexing.py?line=1938'>1939</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_maybe_update_cacher(clear\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1279\u001b[0m, in \u001b[0;36mSeries._maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy, inplace)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1273'>1274</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cacher\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1274'>1275</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(ref) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m ref\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1275'>1276</a>\u001b[0m     \u001b[39m# GH#42530 self.name must be in ref.columns\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1276'>1277</a>\u001b[0m     \u001b[39m# to ensure column still in dataframe\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1277'>1278</a>\u001b[0m     \u001b[39m# otherwise, either self or ref has swapped in new arrays\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1278'>1279</a>\u001b[0m     ref\u001b[39m.\u001b[39;49m_maybe_cache_changed(cacher[\u001b[39m0\u001b[39;49m], \u001b[39mself\u001b[39;49m, inplace\u001b[39m=\u001b[39;49minplace)\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1279'>1280</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1280'>1281</a>\u001b[0m     \u001b[39m# GH#33675 we have swapped in a new array, so parent\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1281'>1282</a>\u001b[0m     \u001b[39m#  reference to self is now invalid\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/series.py?line=1282'>1283</a>\u001b[0m     ref\u001b[39m.\u001b[39m_item_cache\u001b[39m.\u001b[39mpop(cacher[\u001b[39m0\u001b[39m], \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3956\u001b[0m, in \u001b[0;36mDataFrame._maybe_cache_changed\u001b[1;34m(self, item, value, inplace)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3951'>3952</a>\u001b[0m \u001b[39mif\u001b[39;00m old\u001b[39m.\u001b[39m_values \u001b[39mis\u001b[39;00m value\u001b[39m.\u001b[39m_values \u001b[39mand\u001b[39;00m inplace:\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3952'>3953</a>\u001b[0m     \u001b[39m# GH#46149 avoid making unnecessary copies/block-splitting\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3953'>3954</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3955'>3956</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49miset(loc, arraylike, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1132\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/internals/managers.py?line=1129'>1130</a>\u001b[0m blk_locs \u001b[39m=\u001b[39m blklocs[val_locs\u001b[39m.\u001b[39mindexer]\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/internals/managers.py?line=1130'>1131</a>\u001b[0m \u001b[39mif\u001b[39;00m inplace \u001b[39mand\u001b[39;00m blk\u001b[39m.\u001b[39mshould_store(value):\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/internals/managers.py?line=1131'>1132</a>\u001b[0m     blk\u001b[39m.\u001b[39;49mset_inplace(blk_locs, value_getitem(val_locs))\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/internals/managers.py?line=1132'>1133</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/internals/managers.py?line=1133'>1134</a>\u001b[0m     unfit_mgr_locs\u001b[39m.\u001b[39mappend(blk\u001b[39m.\u001b[39mmgr_locs\u001b[39m.\u001b[39mas_array[blk_locs])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "def hdfs_sampling(df, window='session'):\n",
    "    assert window == 'session', \"Only window=session is supported for HDFS dataset.\"\n",
    "\n",
    "    df['Label']= \"NULL\"\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        blkId_list = re.findall(r'(blk_-?\\d+)', row['Content'])\n",
    "        df['Label'].iloc[idx] = blkId_list\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return df\n",
    "'''        \n",
    "        df[\"BlockId\"]\n",
    "        blkId_set = set(blkId_list)\n",
    "        for blk_Id in blkId_set:\n",
    "            data_dict[blk_Id].append(row[\"EventId\"])\n",
    "\n",
    "    data_df = pd.DataFrame(list(data_dict.items()), columns=['BlockId', 'EventSequence'])\n",
    "    data_df.to_csv(log_sequence_file, index=None)\n",
    "    print(\"hdfs sampling done\")\n",
    "'''\n",
    "aaa_df = hdfs_sampling(train)\n",
    "aaa_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NULL'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Label'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(hdfs_sequence_file, n=None, ratio=0.3):\n",
    "    blk_label_dict = {}\n",
    "    blk_label_file = os.path.join(input_dir, \"anomaly_label.csv\")\n",
    "    blk_df = pd.read_csv(blk_label_file)\n",
    "    for _ , row in tqdm(blk_df.iterrows()):\n",
    "        blk_label_dict[row[\"BlockId\"]] = 1 if row[\"Label\"] == \"Anomaly\" else 0\n",
    "\n",
    "    seq = hdfs_sequence_file.copy() #pd.read_csv(hdfs_sequence_file)\n",
    "    seq[\"Label\"] = seq[\"BlockId\"].apply(lambda x: blk_label_dict.get(x)) #add label to the sequence of each blockid\n",
    "\n",
    "    #normal_seq = seq[seq[\"Label\"] == 0][\"EventSequence\"]\n",
    "    #normal_seq = normal_seq.sample(frac=1, random_state=20) # shuffle normal data\n",
    "\n",
    "    #abnormal_seq = seq[seq[\"Label\"] == 1][\"EventSequence\"]\n",
    "    #normal_len, abnormal_len = len(normal_seq), len(abnormal_seq)\n",
    "    #train_len = n if n else int(normal_len * ratio)\n",
    "    #print(\"normal size {0}, abnormal size {1}, training size {2}\".format(normal_len, abnormal_len, train_len))\n",
    "\n",
    "    #train = seq.iloc[:train_len]\n",
    "    #test_normal = normal_seq.iloc[train_len:]\n",
    "    #test_abnormal = abnormal_seq\n",
    "\n",
    "    #df_to_file(train, output_dir + \"train\")\n",
    "    #df_to_file(test_normal, output_dir + \"test_normal\")\n",
    "    #df_to_file(test_abnormal, output_dir + \"test_abnormal\")\n",
    "    print(\"generate train test data done\")\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "575061it [00:17, 32079.76it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'BlockId'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BlockId'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\KaggleTest\\main_HDFS.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000023?line=0'>1</a>\u001b[0m new__df \u001b[39m=\u001b[39m generate_train_test(train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000023?line=1'>2</a>\u001b[0m new__df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\KaggleTest\\main_HDFS.ipynb Cell 8'\u001b[0m in \u001b[0;36mgenerate_train_test\u001b[1;34m(hdfs_sequence_file, n, ratio)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=5'>6</a>\u001b[0m     blk_label_dict[row[\u001b[39m\"\u001b[39m\u001b[39mBlockId\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m row[\u001b[39m\"\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAnomaly\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=7'>8</a>\u001b[0m seq \u001b[39m=\u001b[39m hdfs_sequence_file\u001b[39m.\u001b[39mcopy() \u001b[39m#pd.read_csv(hdfs_sequence_file)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=8'>9</a>\u001b[0m seq[\u001b[39m\"\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m seq[\u001b[39m\"\u001b[39;49m\u001b[39mBlockId\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: blk_label_dict\u001b[39m.\u001b[39mget(x)) \u001b[39m#add label to the sequence of each blockid\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=10'>11</a>\u001b[0m \u001b[39m#normal_seq = seq[seq[\"Label\"] == 0][\"EventSequence\"]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=11'>12</a>\u001b[0m \u001b[39m#normal_seq = normal_seq.sample(frac=1, random_state=20) # shuffle normal data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=12'>13</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=23'>24</a>\u001b[0m \u001b[39m#df_to_file(test_normal, output_dir + \"test_normal\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=24'>25</a>\u001b[0m \u001b[39m#df_to_file(test_abnormal, output_dir + \"test_abnormal\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/jads/AnomalyDetection_Transformers/KaggleTest/main_HDFS.ipynb#ch0000022?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgenerate train test data done\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\jads\\AnomalyDetection_Transformers\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/jads/AnomalyDetection_Transformers/.venv/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BlockId'"
     ]
    }
   ],
   "source": [
    "new__df = generate_train_test(train)\n",
    "new__df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.loc[:12000,:]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the maximum number of words in a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment_text'].apply(lambda x:len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing a function for getting auc score for validation\n",
    "\n",
    "def roc_auc(predictions,target):\n",
    "    '''\n",
    "    This methods returns the AUC Score when given the Predictions\n",
    "    and Labels\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n",
    "                                                  stratify=train.toxic.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 1500\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "#zero pad the sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     input_length=max_len))\n",
    "    model.add(SimpleRNN(100))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync) #Multiplying by Strategy to run on TPU's"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4a2be7d9a8e225bb2e573ddefdac0c561e4de6358d3dd5bc426a91fd95e2205"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
